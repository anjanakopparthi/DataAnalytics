{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "432001932_hw1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CSCE 676 :: Data Mining and Analysis :: Texas A&M University :: Spring 2022\n",
        "\n",
        "\n",
        "# Homework 1: Let's GOOOOO!\n",
        "\n",
        "- **100 points [7% of your final grade]**\n",
        "- **Due Tuesday, February 13 by 11:59pm**\n",
        "\n",
        "***Goals of this homework:***\n",
        "1. Collect data from the web, clean it, and then make some observations based on exploratory data analysis\n",
        "2. Understand and implement the classic apriori algorithm and extensions to find the association rules in a movie rating dataset\n",
        "\n",
        "***Submission instructions:***\n",
        "\n",
        "You should post your notebook to Canvas (look for the homework 1 assignment there). Please name your submission **your-uin_hw1.ipynb**, so for example, my submission would be something like **555001234_hw1.ipynb**. Your notebook should be fully executed when you submit ... so run all the cells for us so we can see the output, then submit that. \n",
        "\n",
        "***Late Days:***\n",
        "\n",
        "As a reminder, you may use up to three of your late days on this homework, meaning the latest we will accept it is February 16 by 11:59pm.\n",
        "\n",
        "***Collaboration declaration:***\n",
        "\n",
        "If you worked with someone on this homework, please be sure to mention that. Remember to include citations to any sources you use in the homework."
      ],
      "metadata": {
        "id": "Ak3SqhmRDYKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (50 points) Part 1: UFOs"
      ],
      "metadata": {
        "id": "iiUzZn-6Ecs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (10pts) Part 1a: UFOs are Out There, But First I Need to Store them Locally\n",
        "\n",
        "For this first part, we're going to collect evidence of UFO sightings from the **National UFO Reporting Center**. Specifically, we're going \n",
        "to focus only on UFO sightings in Texas, as reported at this webpage:\n",
        "\n",
        "* http://www.nuforc.org/webreports/ndxlTX.html\n",
        "\n",
        "Recall that you can view the source of a webpage in Chrome under View &rarr; Developer &rarr; View Source. \n",
        "You'll notice, however, that this raw HTML is not in our friendly csv format and so will require some initial pre-processing. \n",
        "In particular, we're going to use the Python libraries **[requests](http://docs.python-requests.org/en/master/)** \n",
        "and **[beautiful soup](https://www.crummy.com/software/BeautifulSoup/)** to convert this UFO data from its original HTML format into csv. \n",
        "\n",
        "Hints:\n",
        "* You'll notice that the column headers are in the `<TH>` tags.\n",
        "* The values are in the `<TD>` tags.\n",
        "* In beautiful soup, something like `.find_all('td')` may help you.\n",
        "* To write the csv, you might want to `import csv` and take a look at the functions provided.\n",
        "* If you google for \"beautifulsoup table to csv\" you should find some nice starting points.  Note, however, that you may not use an existing method that auto-magically converts the HTML into csv; we expect you to write your own code. If you borrow some elements from online resources, you should cite them in the comments. "
      ],
      "metadata": {
        "id": "oHXUGi-gm88u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# you should use requests to get the webpage, then extract \n",
        "# the appropriate column headings and rows\n",
        "# then write this out to csv to a local file called 'ufos_in_texas.csv'\n",
        "\n",
        "# Include all the packages needed\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib3\n",
        "import csv  \n",
        "\n",
        "# Path to extract data\n",
        "url = \"http://www.nuforc.org/webreports/ndxlTX.html\"\n",
        "\n",
        "# Using requests HTTP Library to fetch UFO data # The get() method sends a GET request to the specified url. The get() method returns a requests.Response object.\n",
        "url_content = requests.get(url).text            # Downloading content from webpage\n",
        "soup = BeautifulSoup(url_content,'html.parser') # Creating beautifulsoup object\n",
        "\n",
        "# Sometimes we might have more than one table and the table might not have labels but instead classes, this is a quick check to figure out if we have labels or not.\n",
        "# for table in soup.find_all('table'):\n",
        "#     print(table.get('class'))\n",
        "## We have only one table and we have row labels in order\n",
        "\n",
        "# Get all tables, store as list\n",
        "tables = soup.find_all('table')\n",
        "table = tables[0] # Get the first table\n",
        "\n",
        "# Dummy List's to store rows and columns \n",
        "row_data = []\n",
        "headers_data = []\n",
        "\n",
        "# To collect column headers we need to find all tags with <TH> tags\n",
        "for column in table.findAll('th'):\n",
        "    headers_data.append(column.text)\n",
        "print(headers_data)\n",
        "\n",
        "# To collect all the rows and columns from the table\n",
        "rows = table.find_all('tr')\n",
        "temp_col = table.findAll('th')\n",
        "\n",
        "\n",
        "for row in rows:\n",
        "    singlerow = {}\n",
        "    for td, th in zip(row.findAll(\"td\"), headers_data) :\n",
        "        singlerow[th] = td.text\n",
        "    row_data.append(singlerow)\n",
        "\n",
        "  \n",
        "with open('ufos_in_texas.csv', 'w') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames = headers_data)\n",
        "    writer.writeheader()\n",
        "    for row in row_data:\n",
        "      if row:\n",
        "        writer.writerow(row)\n",
        "\n",
        "# To check how the data is stored\n",
        "# temp = pd.read_csv(\"UFOdata.csv\")\n",
        "# print(temp.head())\n",
        "\n",
        "# There are some rows with NaN. Hence added a line not to load such data \n",
        "\n",
        "# https://medium.com/geekculture/web-scraping-tables-in-python-using-beautiful-soup-8bbc31c5803e\n",
        "# https://www.tutorialspoint.com/how-to-save-html-tables-data-to-csv-in-python\n",
        "# https://www.kite.com/python/examples/4420/beautifulsoup-parse-an-html-table-and-write-to-a-csv\n"
      ],
      "metadata": {
        "id": "R7e6aYoQEYTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a594fa93-efa3-447f-9faa-ec4a57443582"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Date / Time', 'City', 'State', 'Shape', 'Duration', 'Summary', 'Posted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have your local csv file, you should read it in and then issue the .head() command."
      ],
      "metadata": {
        "id": "BfQTWXRfnEZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "UFOdata = pd.read_csv(\"ufos_in_texas.csv\")\n",
        "UFOdata.head()"
      ],
      "metadata": {
        "id": "lGjL27fsnEIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2ca96b8e-327d-45ec-caa5-e4c805363248"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4bad516e-97b3-48bf-95b7-aa766cf1c26f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date / Time</th>\n",
              "      <th>City</th>\n",
              "      <th>State</th>\n",
              "      <th>Shape</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Posted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12/14/21 22:30</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Formation</td>\n",
              "      <td>8 minutes</td>\n",
              "      <td>It was loud like rocket in a V shape.</td>\n",
              "      <td>12/19/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12/12/21 17:30</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Light</td>\n",
              "      <td>10 minutes</td>\n",
              "      <td>A light that was fading in and out.</td>\n",
              "      <td>12/19/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12/9/21 16:30</td>\n",
              "      <td>Lazerbet</td>\n",
              "      <td>TX</td>\n",
              "      <td>Other</td>\n",
              "      <td>Google maping</td>\n",
              "      <td>It's big</td>\n",
              "      <td>12/19/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12/9/21 16:00</td>\n",
              "      <td>Lazerbet</td>\n",
              "      <td>TX</td>\n",
              "      <td>Triangle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unhuman</td>\n",
              "      <td>12/19/21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12/7/21 17:30</td>\n",
              "      <td>Oak Cliff</td>\n",
              "      <td>TX</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I was randomly taking pictures of the clouds a...</td>\n",
              "      <td>12/19/21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bad516e-97b3-48bf-95b7-aa766cf1c26f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bad516e-97b3-48bf-95b7-aa766cf1c26f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bad516e-97b3-48bf-95b7-aa766cf1c26f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Date / Time  ...    Posted\n",
              "0  12/14/21 22:30  ...  12/19/21\n",
              "1  12/12/21 17:30  ...  12/19/21\n",
              "2   12/9/21 16:30  ...  12/19/21\n",
              "3   12/9/21 16:00  ...  12/19/21\n",
              "4   12/7/21 17:30  ...  12/19/21\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (15pts) Part 1b: UFOs are a Mess! Time to Clean Up!\n",
        "\n",
        "Okay, now we move to the fun part -- making sense of this messy data. These UFO reports are user-generated with little input validation. As a result, you will notice lots of oddities. \n",
        "\n",
        "Let's begin by focusing on the **Duration** column. As a first pass, let's make a grossly simplifying assumption -- that the only valid data is any duration that is of the form:  \n",
        "\n",
        "* 1 second\n",
        "* 2 seconds\n",
        "* ...\n",
        "* 1 minute\n",
        "* 2 minutes\n",
        "* ...\n",
        "* 1 hour\n",
        "* 2 hours \n",
        "* ...\n",
        "* 1 day\n",
        "* 2 days \n",
        "* ...\n",
        "\n",
        "That is, we will only accept positive integers followed by a space, followed by a properly spelled unit. Every other entry is invalid. For example, that means these are all invalid durations:\n",
        "\n",
        "* 1s\n",
        "* 2 min.\n",
        "* 2-3 seconds\n",
        "* 10-15min\n",
        "* 1 minute+\n",
        "* 30 minutes and longer\n",
        "* about 1.5 minutes\n",
        "\n",
        "You may find the **pandas** library to be very helpful for this part. Create a new pandas dataframe that only includes sightings with these values, **where you convert all durations into seconds**. How many total rows are there in the original dataset? How many rows in your new 'validated' dataset? Report the basic statistics of the duration in your new 'validated' dataset (report maximum, minimum, mean, and standard deviation values of duration). At last, plot a boxplot of the duration (in seconds) in your 'validated' dataset."
      ],
      "metadata": {
        "id": "kCSVPkNOnYfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here \n",
        "# filter our invalid durations\n",
        "# convert all valid durations to seconds\n",
        "\n",
        "import re\n",
        "# Need to check how the data is stored\n",
        "# print(type(UFOdata['Duration'][0]))\n",
        "len(UFOdata)\n",
        "\n",
        "# Valid data is any duration that is of the form mentioned above. \n",
        "# Syntax Series.str.extract(*args, **kwargs) # pat (str) - Regular expression pattern with capturing groups; flags = re\n",
        "# flags (int), default 0 (no flags) -Flags from the re module; \\d - Matches any decimal digit. Equivalent to any single numeral 0 to 9. {} - Whatever precedes braces {n} will be repeated at least n times.\n",
        "# \\s - Matches where a string contains any whitespace character. Equivalent to any space, tab, or newline charecter. (Think of this as matching \"space\" charecters.)\n",
        "\n",
        "pat = '^(\\d+\\s+(days|day|hours|hour|minutes|minute|seconds|second|week|weeks|month|months|year|years))$'\n",
        "UFO_clean1 = UFOdata.loc[UFOdata['Duration'].str.match(pat, na = False, flags = re.I)]\n",
        "len(UFO_clean1)\n",
        "\n",
        "durations_sec = []\n",
        "count = 0\n",
        "for i, row in UFO_clean1.iterrows():\n",
        "  row = UFO_clean1['Duration'][i]\n",
        "  d = row.lower().split()\n",
        "  t = int(d[0])\n",
        "  \n",
        "  #print(row['Duration'][0])\n",
        "  if(d[1] == \"minute\" or d[1] == \"minutes\"):\n",
        "    t = t*60\n",
        "  elif(d[1] == \"hour\" or d[1] == \"hours\"):\n",
        "    t = t*3600\n",
        "  elif(d[1] == \"day\" or d[1] == \"days\"):\n",
        "    t = t*24*3600\n",
        "  elif(d[1] == \"week\" or d[1] == \"weeks\"):\n",
        "    t = t*7*24*3600\n",
        "  elif(d[1] == \"month\" or d[1] == \"months\"):\n",
        "    t = t*30*24*3600\n",
        "  elif(d[1] == \"year\" or d[1] == \"years\"):\n",
        "    t = t*365*24*3600\n",
        "  durations_sec.append(t)\n",
        "#  count = count+1\n",
        "\n",
        "#print(count)\n",
        "\n",
        "# https://re-thought.com/python-regex-example-for-pattern-2-digits-to-2-digits-26-to-40/"
      ],
      "metadata": {
        "id": "wMC-mq6wEnnY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple check to test the data cleabed\n",
        "# print(UFO_clean1['Duration'].head())\n",
        "\n",
        "# d = UFO_clean1['Duration'].head()\n",
        "# print(d)\n",
        "#len(durations_sec)"
      ],
      "metadata": {
        "id": "bfseaHgRkzmb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# total rows in original dataset\n",
        "# valid rows in your new 'validated' dataset\n",
        "\n",
        "print(\"total rows in original dataset: \"+ str(len(UFOdata)))\n",
        "# valid rows in your new 'validated' dataset\n",
        "print(\"valid rows in your new 'validated' dataset: \"+str(len(UFO_clean1)))"
      ],
      "metadata": {
        "id": "6Yio0HTHncIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19a2a9c-e318-4529-c728-8e0ec667829f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total rows in original dataset: 5631\n",
            "valid rows in your new 'validated' dataset: 2956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can just use describe function to get the stats\n",
        "#from pandas import DataFrame\n",
        "pd.DataFrame(durations_sec).describe()\n",
        "#pd.DataFrame(durations_sec).plot.box(grid = True)\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.boxplot(durations_sec)"
      ],
      "metadata": {
        "id": "GRYdl1ihJA5R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "bcc3841b-7a4e-4305-9f89-7d0b6603a4cf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-76cb6dc0-b858-4cc3-a4c5-44c6f8cbec6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.956000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.491965e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.900195e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.800000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.576800e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76cb6dc0-b858-4cc3-a4c5-44c6f8cbec6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76cb6dc0-b858-4cc3-a4c5-44c6f8cbec6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76cb6dc0-b858-4cc3-a4c5-44c6f8cbec6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  0\n",
              "count  2.956000e+03\n",
              "mean   5.491965e+04\n",
              "std    2.900195e+06\n",
              "min    1.000000e+00\n",
              "25%    2.000000e+01\n",
              "50%    1.800000e+02\n",
              "75%    6.000000e+02\n",
              "max    1.576800e+08"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# report the basic statistics of duration in 'validated' dataset\n",
        "# boxplot code here\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"max duration in validated dataset (in seconds):\"+ str(np.max(durations_sec)))\n",
        "print(\"min duration in validated dataset (in seconds):\"+ str(np.min(durations_sec)))\n",
        "print(\"mean duration in validated dataset (in seconds):\"+ str(np.mean(durations_sec)))\n",
        "print(\"standard deviation in validated dataset (in seconds):\"+ str(np.std(durations_sec)))\n",
        "\n",
        "fig = plt.subplot()\n",
        "fig.boxplot(durations_sec)\n",
        "fig.set_yscale('log')\n"
      ],
      "metadata": {
        "id": "5VSAJpk6nd6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "19ecb5b6-3199-4340-c308-1e05f0dea169"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max duration in validated dataset (in seconds):157680000\n",
            "min duration in validated dataset (in seconds):1\n",
            "mean duration in validated dataset (in seconds):54919.65257104195\n",
            "standard deviation in validated dataset (in seconds):2899704.1811341476\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (15pts) Part 1c: Can we do better?\n",
        "Interesting. But we threw away a **lot** of data. We can do better. For this part, you will do your best to clean up the durations from your original dataset. Keep in mind some initial guidelines:\n",
        "\n",
        "* If a duration has a range, use the average as its value. For example, if the duration is listed as “6-8 minutes”, you should consider the duration as “7 minutes”. (Again, you will need to eventually convert minutes into seconds).\n",
        "* If a duration has a “<” sign, you should simply ignore the “<” sign. For example if the duration is specified as “< 1 minute”, consider the duration to be “1 minute”. You should subsequently convert “1 minute” to \"60 seconds\".\n",
        "* If a duration has a “>” sign, you should simply ignore the “>” sign. \n",
        "* You should ignore any row with an empty duration.\n",
        "\n",
        "You will probably have to improvise as you go along, so **make detailed notes of what decisions you are making and why**."
      ],
      "metadata": {
        "id": "XRED23qlni_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here \n",
        "# clean data \n",
        "# convert cleaned durations to seconds\n",
        "# +2 min, 2+mins\n",
        "\n",
        "pat = '^(\\d+\\s*(?i)(sec|secs|second|seconds|minutes|min|mins|minute|hr|hrs|hour|hours|day|days|week|weeks|month|months|year|years))$' #Used in 1.b Ex: \"8 minutes\"\n",
        "pat1 = '^(\\d+\\\\-\\d+\\s*(?i)(sec|secs|second|seconds|min|mins|minutes|minute|hr|hrs|hour|hours|day|days|week|weeks|month|months|year|years))$' #To capture the following 4-6;  #s* = 0 or more occurances\n",
        "pat2 = '^((\\\\<|\\\\>|\\~)\\s*\\d+\\s*(?i)(sec|secs|second|seconds|minutes|min|mins|minute|hr|hrs|hour|hours|day|days|week|weeks|month|months|year|years))$'#To capture > or < sybmols containing durations\n",
        "\n",
        "\n",
        "UFO_clean2 = UFOdata.loc[UFOdata['Duration'].str.match(pat1, na = False, flags = re.U)| UFOdata['Duration'].str.match(pat2, na = False, flags = re.I)| UFOdata['Duration'].str.match(pat, na = False, flags = re.I)]\n",
        "len(UFO_clean2)\n",
        "\n",
        "durations2_sec = []\n",
        "\n",
        "for i, row in UFO_clean2.iterrows():\n",
        "  row = UFO_clean2['Duration'][i]\n",
        "  row = row.lower()\n",
        "  vals = re.findall('[0-9]+', row)  # To capture all the digits in the duration\n",
        "  num_list = [int(i) for i in vals] # To ennumarate them to find mean\n",
        "  t  = np.mean(num_list)\n",
        "  \n",
        "  #print(row['Duration'][0])\n",
        "  if(row.find(\"min\") != -1):\n",
        "    t = t*60\n",
        "  elif(row.find(\"hour\") != -1):\n",
        "    t = t*3600\n",
        "  elif(row.find(\"day\") != -1):\n",
        "    t = t*24*3600\n",
        "  elif(row.find(\"week\") != -1):\n",
        "    t = t*7*24*3600\n",
        "  elif(row.find(\"month\") != -1):\n",
        "    t = t*30*24*3600\n",
        "  elif(row.find(\"year\") != -1):\n",
        "    t = t*365*24*3600\n",
        "  durations2_sec.append(t)\n",
        "\n",
        "# https://www.programiz.com/python-programming/regex"
      ],
      "metadata": {
        "id": "q3zORgUTnmZg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#durations2_sec"
      ],
      "metadata": {
        "id": "IZfCu9gF_p-c"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# total rows in original dataset\n",
        "# valid rows in your cleaned dataset\n",
        "\n",
        "print(\"total rows in original dataset: \"+ str(len(UFOdata)))\n",
        "print(\"valid rows in your new cleaned dataset: \"+str(len(UFO_clean2)))"
      ],
      "metadata": {
        "id": "e2PDFUk1nqY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b458eb7-306f-4df1-f888-79fd402089ce"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total rows in original dataset: 5631\n",
            "valid rows in your new cleaned dataset: 4045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# report the basic statistics of duration in your cleaned dataset\n",
        "# draw a boxplot for your cleaned dataset\n",
        "\n",
        "print(\"max duration in validated dataset (in seconds):\"+ str(np.max(durations2_sec)))\n",
        "print(\"min duration in validated dataset (in seconds):\"+ str(np.min(durations2_sec)))\n",
        "print(\"mean duration in validated dataset (in seconds):\"+ str(np.mean(durations2_sec)))\n",
        "print(\"standard deviation in validated dataset (in seconds):\"+ str(np.std(durations2_sec)))\n",
        "\n",
        "fig = plt.subplot()\n",
        "fig.boxplot(durations2_sec)\n",
        "fig.set_yscale('log')"
      ],
      "metadata": {
        "id": "L_r7ogIHnquU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "c59fe459-a72b-401d-ef37-54b8ab584e41"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max duration in validated dataset (in seconds):157680000.0\n",
            "min duration in validated dataset (in seconds):1.0\n",
            "mean duration in validated dataset (in seconds):40292.75278121137\n",
            "standard deviation in validated dataset (in seconds):2478946.712062056\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(durations2_sec).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "TY_s7Wplnsf7",
        "outputId": "5795c62c-998f-4727-fa38-841686d94857"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0836c9e9-570e-479c-9889-15d0b53860d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.045000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.029275e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.479253e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.500000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.576800e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0836c9e9-570e-479c-9889-15d0b53860d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0836c9e9-570e-479c-9889-15d0b53860d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0836c9e9-570e-479c-9889-15d0b53860d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  0\n",
              "count  4.045000e+03\n",
              "mean   4.029275e+04\n",
              "std    2.479253e+06\n",
              "min    1.000000e+00\n",
              "25%    2.000000e+01\n",
              "50%    1.500000e+02\n",
              "75%    6.000000e+02\n",
              "max    1.576800e+08"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (5pts) Part 1d: Observations and Conclusions\n",
        "\n",
        "Based on your analysis on part 1b and 1c, what observations or conclusions can you make from the data?"
      ],
      "metadata": {
        "id": "-5rKvm1k7HHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your answer here*\n",
        "\n",
        "1.   If we are stringent on the data entry format/specification (like in part 1b)  we miss out of on lot of data.\n",
        "2.   In part 1b, only about 52.5% data was captured, while in part 1c, about 72% data was captured as techniques like (mean and approximation are used). \n",
        "3. Capturing more instances reduced the mean considerably.\n",
        "4. More outliers are observed in 1.c\n",
        "5. There are still some uncaptured patterns where units are missing, formats like '00:05', 'few seconds', 'Minutes' and '~5 min'. Depending on the requirement one can try clean the data to capture many more patterns.\n",
        "\n"
      ],
      "metadata": {
        "id": "vrnseH_t7RzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (5pts) Part 1e: Next Steps\n",
        "\n",
        "Now is your chance to conduct an interesting analysis on the UFO data you have collected. This is open-ended, so you may choose whatever direction you like. For example, you might want to take a look at the shape of the UFOs or perhaps the temporal aspects of the reports. "
      ],
      "metadata": {
        "id": "X-n9Zd2j7uFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import unique\n",
        "from numpy.ma.core import count\n",
        "# your code here\n",
        "# I think the size of UFO sightings \n",
        "\n",
        "UFOshapes = UFOdata['Shape']\n",
        "uniqshape = UFOshapes.unique()\n",
        "\n",
        "from collections import Counter\n",
        "Counter(UFOshapes)\n"
      ],
      "metadata": {
        "id": "GngkwXtD8Kvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c53a344-1669-4761-d21e-19bf6165af86"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Changing': 151,\n",
              "         'Chevron': 77,\n",
              "         'Cigar': 161,\n",
              "         'Circle': 520,\n",
              "         'Cone': 19,\n",
              "         'Cross': 13,\n",
              "         'Cylinder': 94,\n",
              "         'Delta': 1,\n",
              "         'Diamond': 87,\n",
              "         'Disk': 344,\n",
              "         'Egg': 44,\n",
              "         'Fireball': 302,\n",
              "         'Flash': 90,\n",
              "         'Formation': 188,\n",
              "         'Light': 1136,\n",
              "         'Other': 440,\n",
              "         'Oval': 299,\n",
              "         'Rectangle': 108,\n",
              "         'Sphere': 342,\n",
              "         'Teardrop': 61,\n",
              "         'Triangle': 560,\n",
              "         'Unknown': 427,\n",
              "         'cigar': 2,\n",
              "         'diamond': 1,\n",
              "         'light': 5,\n",
              "         nan: 153,\n",
              "         'other': 1,\n",
              "         'rectangle': 1,\n",
              "         'sphere': 1,\n",
              "         'triangle': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*tell us what next steps you took, and what you discovered*\n",
        "\n",
        "\n",
        "> Unique function is used to identify the shapes of UFOs sighted and counter to compute the respective frequencies. Most of the UFOs cited are in expected shapes like circular, disc, triangle as expected. However, the sighting of light shaped UFO are the most common. (seemed strange!!)\n",
        "\n"
      ],
      "metadata": {
        "id": "tb6tGIBG8M2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (50 points) Part 2: Association Rules in Movie Rating Behaviors"
      ],
      "metadata": {
        "id": "FQ6FjJ2NEoFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the second part of this homework, we're going to examine movies using our understanding of association rules, to find movies that \"go together\". For this part, you will implement the apriori algorithm, and apply it to a movie rating dataset. We'll use the [MovieLens](https://grouplens.org/datasets/movielens/) dataset.\n",
        "\n",
        "First, run the next cell to load the dataset we are going to use."
      ],
      "metadata": {
        "id": "CKVTACJGFGYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib3\n",
        "import zipfile\n",
        "\n",
        "http = urllib3.PoolManager()\n",
        "req = http.request(\"GET\", \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\", preload_content=False)\n",
        "\n",
        "with open(\"movie.zip\", 'wb') as out:\n",
        "  while True:\n",
        "    data = req.read(4096)\n",
        "    if not data:\n",
        "      break\n",
        "    out.write(data)\n",
        "req.release_conn()\n",
        "\n",
        "zFile = zipfile.ZipFile(\"movie.zip\", \"r\")\n",
        "for fileM in zFile.namelist():\n",
        "  zFile.extract(fileM)"
      ],
      "metadata": {
        "id": "fcZSAoCAFDyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83bfc7f-36c5-4fd8-c840-01da4d0d098f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ml-latest-small/"
      ],
      "metadata": {
        "id": "YgIIGQ3lIgRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c776d04f-451e-490d-af69-c020b0ed4c8c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "links.csv  movies.csv  ratings.csv  README.txt\ttags.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset, there are four columns: `userId` is the integer ids of users, `movieId` is the integer ids of movies, `rating` is the rate of the user gives to the movie, and `timestamp` which we do not use here. Each row denotes that the user of given `userId` rated the movie of the given `movieId`. We are going to treat each user as a \"basket\", so you will need to collect all the movies that have been rated by a single user as a basket. \n",
        "\n",
        "Now, you need to implement the apriori algorithm and apply it to this dataset to find association rules of user rating behaviors where:\n",
        "\n",
        "1. Define `rating` >= 3 is \"like\" (that is, only consider movie ratings of 3 or higher in your baskets; you may ignore all others)\n",
        "2. `minsup` == 150 (out of 600 users/baskets); we may adjust this based on the discussion on Campuswire\n",
        "3. `minconf` == 0.8 to be determined by a discussion on Campuswire. You may try several different choices, but we will converge on a good choice for everyone for the final submission.\n",
        " \n",
        "We know there are many existing implementations of apriori online (check github for some good starting points). You are welcome to read existing codebases and let that inform your approach. Do not copy-paste any existing code. We want your code to have sufficient comments to explain your steps, to show us that you really know what you are doing. Furthermore, you should add print statements to print out the intermediate steps of your method -- e.g., the size of the candidate set at each step of the method, the size of the filtered set, and any other important information you think will highlight the method. \n",
        "\n",
        "To help get you started, we can load the ratings with the following code snippet:"
      ],
      "metadata": {
        "id": "RiF1Gc0q7qzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# read user ratings\n",
        "allRatings = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
        "allRatings"
      ],
      "metadata": {
        "id": "0y8yZnEVI3Oy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5b6794c5-6ce7-4726-8194-c2a0c7aca1f4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5dd64771-6802-4e3f-aff3-a084bd245d0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100831</th>\n",
              "      <td>610</td>\n",
              "      <td>166534</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1493848402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100832</th>\n",
              "      <td>610</td>\n",
              "      <td>168248</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1493850091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100833</th>\n",
              "      <td>610</td>\n",
              "      <td>168250</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1494273047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100834</th>\n",
              "      <td>610</td>\n",
              "      <td>168252</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1493846352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100835</th>\n",
              "      <td>610</td>\n",
              "      <td>170875</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1493846415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100836 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd64771-6802-4e3f-aff3-a084bd245d0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dd64771-6802-4e3f-aff3-a084bd245d0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dd64771-6802-4e3f-aff3-a084bd245d0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        userId  movieId  rating   timestamp\n",
              "0            1        1     4.0   964982703\n",
              "1            1        3     4.0   964981247\n",
              "2            1        6     4.0   964982224\n",
              "3            1       47     5.0   964983815\n",
              "4            1       50     5.0   964982931\n",
              "...        ...      ...     ...         ...\n",
              "100831     610   166534     4.0  1493848402\n",
              "100832     610   168248     5.0  1493850091\n",
              "100833     610   168250     5.0  1494273047\n",
              "100834     610   168252     5.0  1493846352\n",
              "100835     610   170875     3.0  1493846415\n",
              "\n",
              "[100836 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (15pts) Step 1: Implement Apriori Algorithm\n",
        "In this section, you need to implement the Apriori algorithm, we will check the correctness of your code and we encourage efficient implementation and skills of pruning."
      ],
      "metadata": {
        "id": "QfwWA4d2Ne6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "#Include all the necessary packages\n",
        "from collections import defaultdict\n",
        "from itertools import chain, combinations\n",
        "\n",
        "# Only concerned about movies with ratings (>=3)\n",
        "goodRatings = allRatings[allRatings['rating']>=3]\n",
        "\n",
        "# We have entries where each row gives ratings for one movie given by one users.\n",
        "# We are going to treat each user as a \"basket\", so will need to collect all the movies that have been rated by a single user as a basket. \n",
        "IDgrps = goodRatings.groupby('userId')        #Grouping data by userIDs\n",
        "userId = IDgrps.groups.keys()                 # Collecting all keys - userIDs\n",
        "mvId   = []\n",
        "\n",
        "for i in userId:\n",
        "    mvId.append((IDgrps.get_group(i).movieId.values))\n",
        "\n",
        "# Lets add Headers - userId and movieId\n",
        "temp = pd.DataFrame({'userId':userId,'movieId':mvId})\n",
        "Dataset = temp.movieId\n",
        "\n",
        "# Test Bench\n",
        "# print(\"Baskets - movies rated by a single user\\n\")\n",
        "# print(Dataset)\n",
        "# https://datagy.io/pandas-groupby/ # Groupby guide"
      ],
      "metadata": {
        "id": "fJqM6Ztn8fg-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prune the itemsets - removes itemsets which is not currently in freq itemset  \n",
        "# Takes current itemset, next itemset and length as input argumnets and returns pruned itemset\n",
        "\n",
        "def pruner(nextSet, currentSet, l):\n",
        "  newSet = nextSet.copy()         # To make a copy  \n",
        "  for i in nextSet:\n",
        "    subsets = combinations(i, l)  # All possible combinations\n",
        "    for s in subsets:\n",
        "      if(frozenset(s) not in currentSet):\n",
        "        newSet.remove(i)\n",
        "        break\n",
        "  return newSet"
      ],
      "metadata": {
        "id": "IIHmBH1Mu3I4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find assosiation rules from formed itemset\n",
        "# Takes frequent itemsets and minimum confidence as inputs and return rules\n",
        "\n",
        "def associationRules(freqItemSet, itemSetWithSup, minConf):\n",
        "  rules = []\n",
        "  for k, i in freqItemSet.items():\n",
        "    for j in i:\n",
        "      subsets = chain.from_iterable(combinations(j, l) for l in range(1, len(j)))\n",
        "      for s in subsets:\n",
        "        confidence = float(itemSetWithSup[j] / itemSetWithSup[frozenset(s)])\n",
        "        if(confidence >= minConf):\n",
        "          rules.append([list(s) , list(j.difference(s))])\n",
        "  return rules"
      ],
      "metadata": {
        "id": "oOBhHDUavdVh"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequent Itemsets is used to generate frequent itemsets\n",
        "# Takes itemset, data, minimum support, final item set with support, alpha factor, minimum support scaling factor.\n",
        "\n",
        "def freqItemSets(itemSet, totalData, minSup, finalItemSetWithSup, aF, minsup_SF):\n",
        "  freqItemSet = set()\n",
        "  temp = defaultdict(int)\n",
        "  for i in itemSet:\n",
        "    for itemSet in totalData:\n",
        "      if i.issubset(itemSet):\n",
        "        finalItemSetWithSup[i] += 1\n",
        "        temp[i] += 1\n",
        "  for i, count in temp.items():\n",
        "          sup = count\n",
        "          if(sup >= minSup*minsup_SF*aF):\n",
        "            freqItemSet.add(i)\n",
        "  return freqItemSet"
      ],
      "metadata": {
        "id": "b4NruZ5gwEmH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apriori algorithm implementation\n",
        "# The function takes in dataframe which has to be mined, minimum support, minimum confidence, alphaFactor and sample factor \n",
        "# This code is can be scalled to 2c \n",
        "\n",
        "def apriori(data, minSup, minConf, aF, minsup_SF):\n",
        "    totalFreqItemsets = []\n",
        "    CandidateItemSet1 = set()\n",
        "    for i in data:\n",
        "        for j in i:\n",
        "             CandidateItemSet1.add(frozenset([j]))\n",
        "\n",
        "    x = str(len(CandidateItemSet1))\n",
        "    #print(\"\\nTotal \"+x+ \" singleton canditates\")\n",
        "   \n",
        "    # Initializations\n",
        "    finalFreqItemSet = dict()\n",
        "    finalItemSetWithSup = defaultdict(int)\n",
        "    \n",
        "    # Frequent itemsets with one element\n",
        "    singletonItemSet = freqItemSets(CandidateItemSet1, data, minSup, finalItemSetWithSup, aF, minsup_SF)\n",
        "    currentFreqSet = singletonItemSet\n",
        "    totalFreqItemsets = totalFreqItemsets + list(currentFreqSet)        # adding current itemsets to total itemsets\n",
        "    \n",
        "    # Continues for itemsets with more than 2 elements\n",
        "    k = 2\n",
        "    # To Calculate frequent item sets\n",
        "    while(currentFreqSet):\n",
        "        x = len(currentFreqSet)\n",
        "        print(\"Total itemsets with size \"+str(k-1)+\" greater than \" +str(minSup*aF*minsup_SF)+\" are \"+str(x)+\"\\n\")\n",
        "        finalFreqItemSet[k-1] = currentFreqSet\n",
        "        # Adding the current itemset to frequent itemset\n",
        "        nextCandidateSet = set([i.union(j) for i in currentFreqSet for j in currentFreqSet if len(i.union(j)) == k])\n",
        "        nextCandidateSet = pruner(nextCandidateSet, currentFreqSet, k-1)\n",
        "        #Swapping current itemet with new one\n",
        "        currentFreqSet = freqItemSets(nextCandidateSet, data, minSup, finalItemSetWithSup, aF, minsup_SF)\n",
        "        totalFreqItemsets = totalFreqItemsets + list(currentFreqSet)\n",
        "        k += 1\n",
        "    \n",
        "    # forming assosiation rules with our finalset an minconfidence\n",
        "    rules = associationRules(finalFreqItemSet, finalItemSetWithSup, minConf)\n",
        "    #print(finalFreqItemSet)\n",
        "    return rules, finalFreqItemSet\n"
      ],
      "metadata": {
        "id": "7AdctM1KkECa"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function - calls all other functions and returns number of itemsets\n",
        "\n",
        "def aprioriAlgo_ItemSet(Dataset, minimumSupport, minConfidence, alphaFactor, minsup_ScalingFactor):\n",
        "  rules, FinalFrequent = apriori(Dataset, minimumSupport, minConfidence, alphaFactor, minsup_ScalingFactor)\n",
        "\n",
        "  finalFrequent = []\n",
        "  for i in list(FinalFrequent.values()):\n",
        "    finalFrequent = finalFrequent + list(i)\n",
        "\n",
        "  print(\"Total frequent itemsets are : \" + str(len(finalFrequent)))\n",
        "  temp = len(finalFrequent)\n",
        "  return temp"
      ],
      "metadata": {
        "id": "RReJYaNk28D2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function call to run appriori algorithm on the dataset\n",
        "a = aprioriAlgo_ItemSet(Dataset, 150, 0.8, 1, 1)\n",
        "\n",
        "# This link was really of great help.\n",
        "# https://towardsdatascience.com/apriori-association-rule-mining-explanation-and-python-implementation-290b42afdfc6\n",
        "# https://github.com/chonyy/apriori_python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhA03YVmFqSh",
        "outputId": "2467f4a4-7f02-485e-895f-ac1d498d5ab1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total itemsets with size 1 greater than 150 are 37\n",
            "\n",
            "Total itemsets with size 2 greater than 150 are 30\n",
            "\n",
            "Total itemsets with size 3 greater than 150 are 2\n",
            "\n",
            "Total frequent itemsets are : 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (5pts) Step 2: Print Your Association Rules\n",
        "\n",
        "Next you should print your final association rules in the following format:\n",
        "\n",
        "**movie_name_1, movie_name_2, ... --> \n",
        "movie_name_k**\n",
        "\n",
        "where the movie names can be fetched by joining the movieId with the file `movies.csv`. For example, one rule that you might find is:\n",
        "\n",
        "**Matrix, The (1999),  Star Wars: Episode V - The Empire Strikes Back (1980),  Star Wars: Episode IV - A New Hope (1977),  -> \n",
        "Star Wars: Episode VI - Return of the Jedi (1983)**"
      ],
      "metadata": {
        "id": "Ea6GbdOOBZOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "# Load dataand extract relevant columns\n",
        "allMovies = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
        "print(allMovies.head())\n",
        "\n",
        "movieData = dict()\n",
        "\n",
        "for i in range(len(allMovies)):\n",
        "  movieData[allMovies.loc[i,'movieId']] = allMovies.loc[i,'title']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMpWtaI77EuM",
        "outputId": "42d75a44-7ce8-41ba-c4f0-6bf7eafe69be"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   movieId  ...                                       genres\n",
            "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
            "1        2  ...                   Adventure|Children|Fantasy\n",
            "2        3  ...                               Comedy|Romance\n",
            "3        4  ...                         Comedy|Drama|Romance\n",
            "4        5  ...                                       Comedy\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To print association rules\n",
        "\n",
        "def printRules(rules):\n",
        "    l = []; r = []; lRules = []; rRules = []  #Initializations\n",
        "    \n",
        "    for i in rules:\n",
        "        l.append(i[0])\n",
        "        r.append(i[1])\n",
        "    \n",
        "    # To generate left side of the association rules\n",
        "    for i in l:\n",
        "        temp = []\n",
        "        for j in range(0,len(i)):\n",
        "            key = i[j]\n",
        "            rule_name = movieData[(key)]\n",
        "            temp.append(movieData[(key)])\n",
        "        lRules.append(temp)\n",
        "\n",
        "    # To generate right side of the association rule\n",
        "    for i in r:\n",
        "        temp = []\n",
        "        for j in range(0,len(i)):\n",
        "            key = i[j]\n",
        "            rule_name = movieData[(key)]\n",
        "            temp.append(rule_name)\n",
        "        rRules.append(temp)\n",
        "\n",
        "    # zipping left side of the association rules with the right side.\n",
        "    rule = list(zip(lRules, rRules))\n",
        "    \n",
        "    # Final list of assoication rule pairs\n",
        "    rules_final=[]\n",
        "    for x in rule:\n",
        "        rules_final.append(list(x))\n",
        "    print(\"Total Association rules are  \"+str(len(rules))+\"\\n\")\n",
        "\n",
        "    count = 0\n",
        "    for x in rules_final:\n",
        "      count = count+1\n",
        "      print(str(count)+str(x[0])+\"  ===>   \"+str((x[1])))"
      ],
      "metadata": {
        "id": "OUXTQDVI8nOv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the rules by runnig apriori algorithm\n",
        "rules, FinalFrequent = apriori(Dataset, 150, 0.8, 1, 1)\n",
        "\n",
        "# Print rules\n",
        "printRules(rules)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfEtVH1d-VNI",
        "outputId": "cb4be40f-74c5-43d2-87da-830a02277b27"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total itemsets with size 1 greater than 150 are 37\n",
            "\n",
            "Total itemsets with size 2 greater than 150 are 30\n",
            "\n",
            "Total itemsets with size 3 greater than 150 are 2\n",
            "\n",
            "Total Association rules are  14\n",
            "\n",
            "1['Lord of the Rings: The Return of the King, The (2003)']  ===>   ['Lord of the Rings: The Fellowship of the Ring, The (2001)']\n",
            "2['Lord of the Rings: The Fellowship of the Ring, The (2001)']  ===>   ['Lord of the Rings: The Return of the King, The (2003)']\n",
            "3['Jurassic Park (1993)']  ===>   ['Forrest Gump (1994)']\n",
            "4['Star Wars: Episode V - The Empire Strikes Back (1980)']  ===>   ['Star Wars: Episode IV - A New Hope (1977)']\n",
            "5['Star Wars: Episode VI - Return of the Jedi (1983)']  ===>   ['Star Wars: Episode IV - A New Hope (1977)']\n",
            "6['Lord of the Rings: The Two Towers, The (2002)']  ===>   ['Lord of the Rings: The Fellowship of the Ring, The (2001)']\n",
            "7['Lord of the Rings: The Fellowship of the Ring, The (2001)']  ===>   ['Lord of the Rings: The Two Towers, The (2002)']\n",
            "8['Star Wars: Episode VI - Return of the Jedi (1983)']  ===>   ['Star Wars: Episode V - The Empire Strikes Back (1980)']\n",
            "9['Seven (a.k.a. Se7en) (1995)']  ===>   ['Pulp Fiction (1994)']\n",
            "10['Lord of the Rings: The Two Towers, The (2002)']  ===>   ['Lord of the Rings: The Return of the King, The (2003)']\n",
            "11['Lord of the Rings: The Return of the King, The (2003)']  ===>   ['Lord of the Rings: The Two Towers, The (2002)']\n",
            "12['Apollo 13 (1995)']  ===>   ['Forrest Gump (1994)']\n",
            "13['Pulp Fiction (1994)', 'Silence of the Lambs, The (1991)']  ===>   ['Shawshank Redemption, The (1994)']\n",
            "14['Silence of the Lambs, The (1991)', 'Shawshank Redemption, The (1994)']  ===>   ['Pulp Fiction (1994)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (15pts) Step 3: Implement Random Sampling\n",
        "\n",
        "We discussed in class a method to randomly sample baskets to avoid the overhead of reading the entire set of baskets (which in practice, could amount to billions of baskets). For this part, you should implement such a random sampling approach that takes a special parameter **alpha** that controls the size of the sample: e.g., alpha = 0.10 means to sample 10% of the baskets (our users, in this case). \n",
        "\n",
        "Vary **alpha** and report the number of frequent itemsets you find and how this compares to the number of frequent itemsets in the entire dataset. What do you discover?\n"
      ],
      "metadata": {
        "id": "FfeufQAxNB82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# No sampling is used, complete apriori algorithm\n",
        "a = aprioriAlgo_ItemSet(Dataset, 150, 0.9, 1, 1)\n",
        "\n",
        "# Generating random samples with aplha as 0.5 and chnaging the minimum support\n",
        "print(\"Aplha value is 0.5 and minsup changes\\n\")\n",
        "b = aprioriAlgo_ItemSet(Dataset.sample(frac=0.5), 150, 0.9, 0.5, 1)\n",
        "c = aprioriAlgo_ItemSet(Dataset.sample(frac=0.5), 150, 0.9, 0.7, 1)\n",
        "d = aprioriAlgo_ItemSet(Dataset.sample(frac=0.5), 150, 0.9, 0.9, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaRRvU-AGe3i",
        "outputId": "3f574d74-3b3d-4fe1-ef45-3d2b09bf10d9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total itemsets with size 1 greater than 150 are 37\n",
            "\n",
            "Total itemsets with size 2 greater than 150 are 30\n",
            "\n",
            "Total itemsets with size 3 greater than 150 are 2\n",
            "\n",
            "Total frequent itemsets are : 69\n",
            "Aplha value is 0.5 and minsup changes\n",
            "\n",
            "Total itemsets with size 1 greater than 75.0 are 32\n",
            "\n",
            "Total itemsets with size 2 greater than 75.0 are 19\n",
            "\n",
            "Total itemsets with size 3 greater than 75.0 are 1\n",
            "\n",
            "Total frequent itemsets are : 52\n",
            "Total itemsets with size 1 greater than 105.0 are 8\n",
            "\n",
            "Total frequent itemsets are : 8\n",
            "Total itemsets with size 1 greater than 135.0 are 3\n",
            "\n",
            "Total frequent itemsets are : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Apriori algorithm run on entire dataset with mimimum support as 150 gives a total of 69 itemsets\\n\")\n",
        "print(\"Apriori algorithm on 50% random sampling of dataset with mimimum support as 75 gives a total of  \"+ str(b))\n",
        "print(\"Apriori algorithm on 50% random sampling of dataset with mimimum support as 105 gives a total of  \"+ str(c))\n",
        "print(\"Apriori algorithm on 50% random sampling of dataset with mimimum support as 135 gives a total of  \"+ str(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FGgOA3cUbEs",
        "outputId": "dc004fa1-554c-4669-9108-3bbcae922e15"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apriori algorithm run on entire dataset with mimimum support as 150 gives a total of 69 itemsets\n",
            "\n",
            "Apriori algorithm on 50% random sampling of dataset with mimimum support as 75 gives a total of  52\n",
            "Apriori algorithm on 50% random sampling of dataset with mimimum support as 105 gives a total of  8\n",
            "Apriori algorithm on 50% random sampling of dataset with mimimum support as 135 gives a total of  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Two experminets were conducted to observe the effects of changes in alpha. Firstly, random sampling was done, 50% of data is chosen at random.Then the minimum support is varied. Secondly number of samples chosen at random is changes. \n",
        "\n",
        "> Observation 1: Increasing minimum support decreases frequent itemsets.\n",
        "\n"
      ],
      "metadata": {
        "id": "ClmeNOe7WnI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing alpha values, i.e, changing the number of samples. \n",
        "print(\"Aplha value is 0.5\\n\")\n",
        "e1 = aprioriAlgo_ItemSet(Dataset.sample(frac=0.5), 150, 0.9, 0.5, 1)\n",
        "print(\"\\n\")\n",
        "print(\"Aplha value is 0.7\\n\")\n",
        "f1 = aprioriAlgo_ItemSet(Dataset.sample(frac=0.7), 150, 0.9, 0.7, 1)\n",
        "print(\"\\n\")\n",
        "print(\"Aplha value is 0.9\\n\")\n",
        "g1 = aprioriAlgo_ItemSet(Dataset.sample(frac=0.9), 150, 0.9, 0.9, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhjYkX4JUacK",
        "outputId": "d6c7064a-f405-49dc-c3c3-77e8dc17623e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplha value is 0.5\n",
            "\n",
            "Total itemsets with size 1 greater than 75.0 are 36\n",
            "\n",
            "Total itemsets with size 2 greater than 75.0 are 30\n",
            "\n",
            "Total itemsets with size 3 greater than 75.0 are 2\n",
            "\n",
            "Total frequent itemsets are : 68\n",
            "\n",
            "\n",
            "Aplha value is 0.7\n",
            "\n",
            "Total itemsets with size 1 greater than 105.0 are 31\n",
            "\n",
            "Total itemsets with size 2 greater than 105.0 are 13\n",
            "\n",
            "Total frequent itemsets are : 44\n",
            "\n",
            "\n",
            "Aplha value is 0.9\n",
            "\n",
            "Total itemsets with size 1 greater than 135.0 are 35\n",
            "\n",
            "Total itemsets with size 2 greater than 135.0 are 29\n",
            "\n",
            "Total itemsets with size 3 greater than 135.0 are 1\n",
            "\n",
            "Total frequent itemsets are : 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"your discussion here\")\n",
        "print(\"Observation2: Increasing value of alpha does not always produce a clear trend in frequent itemsets.\")\n",
        "print(\"Apriori algorithm on 50% random sampling of dataset with mimimum support as 75 gives a total of  \"+ str(e1))\n",
        "print(\"Apriori algorithm on 70% random sampling of dataset with mimimum support as 105 gives a total of  \"+ str(f1))\n",
        "print(\"Apriori algorithm on 90% random sampling of dataset with mimimum support as 135 gives a total of  \"+ str(g1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OA64ZCRdDlN",
        "outputId": "23a7b2c1-696e-45a8-8510-30f271bbf222"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your discussion here\n",
            "Observation2: Increasing value of alpha does not always produce a clear trend in frequent itemsets.\n",
            "Apriori algorithm on 50% random sampling of dataset with mimimum support as 75 gives a total of  68\n",
            "Apriori algorithm on 70% random sampling of dataset with mimimum support as 105 gives a total of  44\n",
            "Apriori algorithm on 90% random sampling of dataset with mimimum support as 135 gives a total of  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (10pts) Step 4: Check for False Positives\n",
        "\n",
        "Next you should verify that the candidate pairs you discover by random sampling are truly frequent by comparing to the itemsets you discover over the entire dataset. \n",
        "\n",
        "For this part, consider another parameter **minsup_sample** that relaxes the minimum support threshold. For example if we want minsup = 1/100 for whole dataset, then try minsup_sample = 1/125 for the sample. This will help catch truly frequent itemsets.\n",
        "\n",
        "Vary **minsup_sample** and report the number of frequent itemsets you find and the number of false positives you find. What do you discover?\n"
      ],
      "metadata": {
        "id": "wLNDiFDrI2-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "# Changing the number of samples from random sampling \n",
        "print(\"Aplha value is 0.5\\n\")\n",
        "e2 = aprioriAlgo_ItemSet(Dataset.sample(frac=0.5), 150, 0.9, 0.5, 0.8)\n",
        "print(\"\\n\")\n",
        "print(\"Aplha value is 0.7\\n\")\n",
        "f2 = aprioriAlgo_ItemSet(Dataset.sample(frac=0.7), 150, 0.9, 0.7, 0.8)\n",
        "print(\"\\n\")\n",
        "print(\"Aplha value is 0.9\\n\")\n",
        "g2 = aprioriAlgo_ItemSet(Dataset.sample(frac=0.9), 150, 0.9, 0.9, 0.8)"
      ],
      "metadata": {
        "id": "R8gtIPuf_82B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af27e93-c481-4dfb-c797-0c582de78a52"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplha value is 0.5\n",
            "\n",
            "Total itemsets with size 1 greater than 60.0 are 61\n",
            "\n",
            "Total itemsets with size 2 greater than 60.0 are 117\n",
            "\n",
            "Total itemsets with size 3 greater than 60.0 are 43\n",
            "\n",
            "Total itemsets with size 4 greater than 60.0 are 2\n",
            "\n",
            "Total frequent itemsets are : 223\n",
            "\n",
            "\n",
            "Aplha value is 0.7\n",
            "\n",
            "Total itemsets with size 1 greater than 84.0 are 54\n",
            "\n",
            "Total itemsets with size 2 greater than 84.0 are 72\n",
            "\n",
            "Total itemsets with size 3 greater than 84.0 are 14\n",
            "\n",
            "Total frequent itemsets are : 140\n",
            "\n",
            "\n",
            "Aplha value is 0.9\n",
            "\n",
            "Total itemsets with size 1 greater than 108.0 are 65\n",
            "\n",
            "Total itemsets with size 2 greater than 108.0 are 112\n",
            "\n",
            "Total itemsets with size 3 greater than 108.0 are 31\n",
            "\n",
            "Total itemsets with size 4 greater than 108.0 are 1\n",
            "\n",
            "Total frequent itemsets are : 209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"your discussion here\")\n",
        "print('The false positive rate for random sampling with 50% datasize and minsup_sample as 0.8, aplha as 0.5 is ' + str(e2-e1))\n",
        "print(\"The false positive rate for random sampling with 70% datasize and minsup_sample as 0.8, aplha as 0.7 is \" + str(int(f2)-int(f1)))\n",
        "print(\"The false positive rate for random sampling with 90% datasize and minsup_sample as 0.8, aplha as 0.9 is \" + str(int(g2) - int(g1)))\n",
        "print(\"No clear trend was observed from false positive rates with the chosen setup\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl8CxZZ6aZS9",
        "outputId": "fbd60454-eb7b-4d10-8381-deb092106d0a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your discussion here\n",
            "The false positive rate for random sampling with 50% datasize and minsup_sample as 0.8, aplha as 0.5 is 155\n",
            "The false positive rate for random sampling with 70% datasize and minsup_sample as 0.8, aplha as 0.7 is 96\n",
            "The false positive rate for random sampling with 90% datasize and minsup_sample as 0.8, aplha as 0.9 is 144\n",
            "No clear trend was observed from false positive rates with the chosen setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (5pts) Step 5: Extensions and Next Steps\n",
        "\n",
        "So far, we have been working with a fairly small dataset. For this last question, try your sampling-based approach on the much larger: **Movies 10M** dataset: https://files.grouplens.org/datasets/movielens/ml-10m.zip\n",
        "\n",
        "First, we need to load this larger dataset:"
      ],
      "metadata": {
        "id": "Wt4JCrwcAHal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib3\n",
        "import zipfile\n",
        "\n",
        "http = urllib3.PoolManager()\n",
        "req = http.request(\"GET\", \"https://files.grouplens.org/datasets/movielens/ml-10m.zip\", preload_content=False)\n",
        "\n",
        "with open(\"movie.zip\", 'wb') as out:\n",
        "  while True:\n",
        "    data = req.read(4096)\n",
        "    if not data:\n",
        "      break\n",
        "    out.write(data)\n",
        "req.release_conn()\n",
        "\n",
        "zFile = zipfile.ZipFile(\"movie.zip\", \"r\")\n",
        "for fileM in zFile.namelist():\n",
        "  zFile.extract(fileM)"
      ],
      "metadata": {
        "id": "iG7qBkj7AVou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf9c3a8-6675-4b9c-8cda-7dc1bd246b4e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ml-10M100K/"
      ],
      "metadata": {
        "id": "6Hi45CqJht7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4076682b-48f3-4385-a251-d37905424945"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allbut.pl  movies.dat  ratings.dat  README.html  split_ratings.sh  tags.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# read user ratings\n",
        "allRatings = pd.read_csv(\"ml-10M100K/ratings.dat\",sep='::', names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"], engine='python')\n",
        "#allRatings \n",
        "goodRatings = allRatings[allRatings['rating']>=3]"
      ],
      "metadata": {
        "id": "V_jdR72WiR2F"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can begin your sampling over this larger dataset."
      ],
      "metadata": {
        "id": "WEX9wu7ewIqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "IDgrps = goodRatings.groupby('userId')        #Grouping data by userIDs\n",
        "userId = IDgrps.groups.keys()                 # Collecting all keys - userIDs\n",
        "mvId   = []\n",
        "\n",
        "for i in userId:\n",
        "    mvId.append((IDgrps.get_group(i).movieId.values))\n",
        "\n",
        "# Lets add Headers - userId and movieId\n",
        "temp = pd.DataFrame({'userId':userId,'movieId':mvId})\n",
        "Dataset = temp.movieId\n",
        "\n"
      ],
      "metadata": {
        "id": "VYRlIEyulq2X"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = aprioriAlgo_ItemSet(Dataset.sample(frac=0.001), 10000, 0.8, 0.002, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLB_m5HYjF2P",
        "outputId": "4fbb9a98-b5d2-418a-de1b-9b6a53e74e28"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total itemsets with size 1 greater than 20.0 are 29\n",
            "\n",
            "Total itemsets with size 2 greater than 20.0 are 24\n",
            "\n",
            "Total frequent itemsets are : 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*your discussion here*\n",
        "\n",
        "\n",
        "> Functions from previous parts of the code are called in this part of the code. Random samples are generated with alpha as 0.001 are generated ie, 10k samples are used. For comparison we had 600 samples initially but now we are running the code on 10k samples. So clearly we are generated on a huge dataset. Here minimum support was 20, minimum confidence was 0.8 and total itemsets observed are 53 (may change when we run the code again). \n",
        "\n"
      ],
      "metadata": {
        "id": "FX3LDkfAlpyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OqandmO25Z_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}